% Notes and exercises on Finite Dimensional Vector Spaces
\documentclass[letterpaper,12pt]{article}
\usepackage{amsmath,amssymb,amsthm,enumitem,fourier}

% Sets
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}

% Relations
\newcommand{\iso}{\cong}

% Operations
\newcommand{\union}{\cup}
\newcommand{\sect}{\cap}
\newcommand{\dsum}{\oplus}

\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\card}{card}
\DeclareMathOperator{\spn}{span}

% Theorems
\theoremstyle{definition}
\newtheorem*{exer}{Exercise}

\theoremstyle{remark}
\newtheorem*{rmk}{Remark}

\newtheoremstyle{direction}{0.5em}{0.5em}{}{}{}{}{0.5em}{}
\theoremstyle{direction}
\newtheorem*{fwd}{\(\implies\)}
\newtheorem*{bwd}{\(\impliedby\)}

% Meta
\title{\textit{Finite Dimensional Vector Spaces}\\Notes and Exercises}
\author{John Peloquin}
\date{}

\begin{document}
\maketitle
\section*{Chapter~I}
\subsection*{\S~7}
\begin{exer}[5]\
\begin{enumerate}
\item[(a)] Two vectors \(\vec{x}=(x_1,x_2)\) and \(\vec{y}=(y_1,y_2)\) in~\(\C^2\) are linearly dependent if and only if \(x_1y_2=x_2y_1\).
\item[(b)] Two vectors \(\vec{x}=(x_1,x_2,x_3)\) and \(\vec{y}=(y_1,y_2,y_3)\) in~\(\C^3\) are linearly dependent if and only if \(x_1y_2=x_2y_1\), \(x_1y_3=x_3y_1\), and \(x_2y_3=x_3y_2\).
\item[(c)] There is no set of three linearly independent vectors in~\(\C^2\).
\end{enumerate}
\end{exer}
\begin{proof}\
\begin{enumerate}
\item[(a)]
\begin{fwd}
Since \(\vec{x}\)~and~\(\vec{y}\) are linearly dependent, there exist scalars \(\alpha,\beta\in\C\) not both zero such that \(\alpha\vec{x}+\beta\vec{y}=0\). If \(\alpha=0\), then \(\beta\ne0\), in which case we must have \(\vec{y}=0\) and the desired equality holds. Similarly if \(\beta=0\). Therefore we may assume \(\alpha\ne0\) and \(\beta\ne0\). We have
\begin{align*}
\alpha x_1&=-\beta y_1\\
\alpha x_2&=-\beta y_2
\end{align*}
Cross multiplying, we have
\[\alpha\beta x_1y_2=\alpha\beta x_2y_1\]
Since \(\alpha\beta\ne0\), the desired equality follows.
\end{fwd}
\begin{bwd}
We consider cases of~\(\vec{x}\):

If \(x_1\ne0\) and \(x_2\ne0\), let \(\alpha=y_1/x_1=y_2/x_2\). Then \(\alpha x_1=y_1\) and \(\alpha x_2=y_2\), so \(\alpha\vec{x}-\vec{y}=0\).

If \(x_1\ne0\) and \(x_2=0\), then \(y_2=0\), so \(\alpha\vec{x}-\vec{y}=0\) where \(\alpha=y_1/x_1\). Similarly if \(x_1=0\) and \(x_2\ne0\).

If \(x_1=0\) and \(x_2=0\), then linear independence is witnessed by \(\vec{x}=0\).
\end{bwd}
\item[(b)]
\begin{fwd}
As in~(a), except that now three cross multiplications are performed to yield the three equations.
\end{fwd}
\begin{bwd}
As in~(a), we consider cases of~\(\vec{x}\ne0\):

If \(x_1\ne0\), \(x_2\ne0\), and \(x_3\ne0\), let \(\alpha=y_1/x_1=y_2/x_2=y_3/x_3\). Then \(\alpha\vec{x}-\vec{y}=0\).

If \(x_i=0\), then \(y_i=0\) and the result follows from~(a) applied to the other coordinates.
\end{bwd}
Note geometrically this result is immediate from~(a) because two vectors in x-y-z space are linearly dependent if and only if their corresponding projections in each of the x-y, x-z, and y-z planes are linearly dependent.
\item[(c)]
We prove that any set of three vectors in~\(\C^2\) is linearly dependent. More specifically, if \(\vec{x},\vec{y},\vec{z}\in\C^2\) and \(\vec{x}\)~and~\(\vec{y}\) are linearly independent, then \(\vec{z}\)~is a linear combination of \(\vec{x}\)~and~\(\vec{y}\).\footnote{Equivalently, any set of two linearly independent vectors in~\(\C^2\) also spans~\(\C^2\) and hence is a basis for~\(\C^2\). See also Theorem~8.2.}

Indeed, suppose \(\vec{x}=(x_1,x_2)\) and \(\vec{y}=(y_1,y_2)\) are linearly independent. By part~(a), \(\delta=x_1y_2-x_2y_1\ne0\). Set
\[
\alpha=\frac{y_2z_1-y_1z_2}{\delta}
\qquad
\beta=\frac{x_1z_2-x_2z_1}{\delta}
\]
It is immediate that \(\alpha\vec{x}+\beta\vec{y}=\vec{z}\), as desired.

Note this result is also immediate from the fact that \(\dim\C^2=2<3\) (see Theorem~8.2).\qedhere
\end{enumerate}
\end{proof}
\begin{exer}[9]
There are 28~basis sets for~\(\C^3\) consisting of binary vectors (vectors each of whose coordinates is 0~or~1).
\end{exer}
\begin{proof}
We count the number of ways to construct a basis set.

There are \(2^3=8\) binary vectors. To construct a basis \emph{sequence}, we choose three linearly independent vectors from this set (Theorem~8.2). We see that there are 7~possible choices for the first vector, namely each of the nonzero binary vectors. For each of these choices, there are 6~possible choices for the second vector, namely each of the remaining nonzero binary vectors. Finally, for each of these \(7\cdot6=42\) choices, there are 4~possible choices for the third vector, namely each of the remaining binary vectors not in the span of the first two. This yields \(7\cdot6\cdot4=168\) possible basis sequences.

Since there are \(3\cdot2\cdot1=6\) sequences for each \emph{set} of three vectors, there are \(7\cdot4=28\) basis sets.
\end{proof}
\subsection*{\S~9}
\begin{exer}[2]
\(\R\)~is not finite dimensional over~\(\Q\).
\end{exer}
\begin{proof}
If it is, then \(\R\iso\Q^n\) for some~\(n\) (Theorem~1). But then
\[2^{\aleph_0}=\card\R=\card\Q^n=(\card\Q)^n=\aleph_0^n=\aleph_0\]
---a contradiction since \(2^{\aleph_0}>\aleph_0\).
\end{proof}
\begin{exer}[4]
Two rational vector spaces with the same cardinality need not be isomorphic.
\end{exer}
\begin{proof}
Consider \(\Q\)~and~\(\Q^2\). We have
\[\card{\Q}=\aleph_0=\aleph_0^2=(\card\Q)^2=\card\Q^2\]
However, \(\dim\Q=1<2=\dim\Q^2\), so \(\Q\not\iso\Q^2\).
\end{proof}
\subsection*{\S~12}
\begin{exer}[2]
If \(V\)~is a vector space and \(M\)~and~\(N\) are subspaces of~\(V\) satisfying \(V\subseteq M\union N\), then \(V=M\) or \(V=N\).
\end{exer}
\begin{proof}
Suppose \(V\ne M\) and \(V\ne N\). Then there exist vectors \(x\in V-M\) and \(y\in V-N\). Since \(V\subseteq M\union N\), we must have \(x\in N\) and \(y\in M\) and \(z=x+y\in M\union N\). But if \(z\in M\) then \(x=z-y\in M\), and if \(z\in N\) then \(y=z-x\in N\)---a contradiction in either case.
\end{proof}
\begin{exer}[6]
Let \(V\)~be a vector space and \(M\)~be a subspace of~\(V\).
\begin{enumerate}
\item[(a)] If \(M\)~is nontrivial (\(M\ne0\) and \(M\ne V\)), then \(M\)~does not have a unique complement.
\item[(b)] If \(V\)~is \(n\)-dimensional and \(M\)~is \(m\)-dimensional, then every complement of~\(M\) is (\(n-m\))-dimensional.
\end{enumerate}
\end{exer}
\begin{proof}\
\begin{enumerate}
\item[(a)] We claim that if \(x\in V-M\), then there exists a complement~\(N\) of~\(M\) with \(x\in N\). Indeed, if \(B\)~is any basis of~\(M\), then \(B\union\{x\}\) is linearly independent in~\(V\) and hence can be extended to a basis~\(B'\) of~\(V\). The subspace \(N=\spn(B'-B)\) is the desired complement.

By this result, if \(M\)~has unique complement~\(N\), then \(V-M\subseteq N\), so that \(V\subseteq M\union N\). But by exercise~2, this implies \(V=M\) or \(V=N\). Since \(M\)~and~\(N\) are complements, \(V=N\) implies \(M=0\). Therefore, \(M\)~must be trivial.
\item[(b)]
If \(N\)~is a complement of~\(M\), let \(\{x_1,\ldots,x_m\}\) be a basis of~\(M\) and \(\{y_1,\ldots,y_k\}\) be a basis of~\(N\). Then \(\{x_1,\ldots,x_m,y_1,\ldots,y_k\}\) is a basis of~\(V\). Indeed, it spans~\(V\) since \(V=M+N\), and it is linearly independent since \(M\sect N=0\). Therefore \(n=m+k\), so \(\dim N=k=n-m\) as desired.\qedhere
\end{enumerate}
\end{proof}
\begin{exer}[7]
Let \(V\)~be a vector space and \(M\)~and~\(N\) be subspaces of~\(V\).
\begin{enumerate}
\item[(a)] If \(V\)~is 5-dimensional and \(M\)~and~\(N\) are 3-dimensional, then \(M\)~and~\(N\) are not disjoint.
\item[(b)] If \(M\)~and~\(N\) are finite dimensional, then
\[\dim M+\dim N=\dim(M+N)+\dim(M\sect N)\]
\end{enumerate}
\end{exer}
\begin{proof}\
\begin{enumerate}
\item[(a)] Since \(M+N\)~is a subspace of~\(V\), \(\dim(M+N)\le5\) (Theorem~1). By part~(b),
\[\dim(M\sect N)=\dim M+\dim N-\dim(M+N)\ge3+3-5=1>0\]
Therefore \(M\sect N\ne0\).
\item[(b)] Let \(m=\dim M\) and \(n=\dim N\). Since \(M\sect N\)~is a subspace of both \(M\)~and~\(N\), we know \(M\sect N\)~is finite dimensional and \(k=\dim(M\sect N)\le\min(m,n)\) (Theorem~1). Let \(\{x_1,\ldots,x_k\}\) be a basis of~\(M\sect N\). Extend it to a basis \(\{x_1,\ldots,x_k,y_1,\ldots,y_{m-k}\}\) of~\(M\) and to a basis \(\{x_1,\ldots,x_k,z_1,\ldots,z_{n-k}\}\) of~\(N\) (Theorem~2). Then
\[\{x_1,\ldots,x_k,y_1,\ldots,y_{m-k},z_1,\ldots,z_{n-k}\}\]
is a basis of~\(M+N\). Indeed, spanning and linear independence follow from the corresponding properties of the bases for \(M\)~and~\(N\). Therefore \(M+N\)~is finite dimensional and
\begin{align*}
\dim(M+N)&=k+(m-k)+(n-k)\\
	&=m+n-k\\
	&=\dim M+\dim N-\dim(M\sect N)\qedhere
\end{align*}
\end{enumerate}
\end{proof}
\begin{rmk}
This result is analogous to the inclusion-exclusion principle for sets:
\[\card(A\union B)=\card A+\card B-\card(A\sect B)\]
\end{rmk}
\section*{Chapter~II}
\subsection*{\S~49}
\begin{exer}[4]
Let \(V\)~be a vector space and \(E\)~and~\(F\) be projections on~\(V\).
\begin{enumerate}[itemsep=0pt]
\item[(a)] \(\ran(E)=\ran(F)\) if and only if \(EF=F\) and \(FE=E\).
\item[(b)] \(\ker(E)=\ker(F)\) if and only if \(EF=E\) and \(FE=F\).
\end{enumerate}
\end{exer}
\begin{proof}
Recall for a projection~\(P\) on~\(V\), \(V=\ran(P)\dsum\ker(P)\) and (Theorem~41.2)
\[\ran(P)=\{\,x\in V\mid Px=x\,\}\qquad\ker(P)=\{\,x\in V\mid Px=0\,\}\]
\begin{enumerate}[itemsep=0pt]
\item[(a)]
\begin{fwd}
If \(x\in V\), then \(Ex\in\ran(E)\subseteq\ran(F)\), so \(FEx=F(Ex)=Ex\). Therefore \(FE=E\). Similarly \(EF=F\).
\end{fwd}
\begin{bwd}
If \(x\in\ran(E)\), then \(x=Eu\) for some \(u\in V\), so
\[Fx=F(Eu)=FEu=Eu=x\]
and hence \(x\in\ran(F)\). Therefore \(\ran(E)\subseteq\ran(F)\). Similarly \(\ran(F)\subseteq\ran(E)\) and hence \(\ran(E)=\ran(F)\).
\end{bwd}
\item[(b)]
\begin{fwd}
Since \(V=\ran(E)\dsum\ker(E)\), if \(x\in V\) there exist \(u\in\ran(E)\) and \(v\in\ker(E)\) with \(x=u+v\). Now
\begin{align*}
FEx&=FE(u+v)&&\\
	&=FEu+FEv&&\\
	&=Fu+F0&&\text{since \(u\in\ran(E)\) and \(v\in\ker(E)\)}\\
	&=Fu+Fv&&\text{since \(\ker(E)\subseteq\ker(F)\)}\\
	&=F(u+v)\\
	&=Fx
\end{align*}
Therefore \(FE=F\). Similarly \(EF=E\).
\end{fwd}
\begin{bwd}
If \(x\in\ker(E)\), then
\[Fx=FEx=F(Ex)=F0=0\]
so \(x\in\ker(F)\). Therefore \(\ker(E)\subseteq\ker(F)\). Similarly \(\ker(F)\subseteq\ker(E)\) and hence \(\ker(E)=\ker(F)\).\qedhere
\end{bwd}
\end{enumerate}
\end{proof}
\begin{rmk}
By (a)~and~(b), \(E=F\) if and only if \(\ran(E)=\ran(F)\) and \(\ker(E)=\ker(F)\). In other words, projections are characterized by their ranges and null spaces.
\end{rmk}

\begin{exer}[5]
If \(E_1,\ldots,E_k\) are projections on~\(V\) with the same range and \(\alpha_1,\ldots,\alpha_k\) are scalars such that \(\sum_i\alpha_i=1\), then \(E=\sum_i\alpha_i E_i\) is a projection.
\end{exer}
\begin{proof}
By Exercise~4(a), we have
\begin{align*}
E^2&=\bigl(\,\sum_i\alpha_iE_i\bigr)^2&&\\
	&=\sum_i\sum_j\alpha_i\alpha_j E_iE_j&&\\
	&=\sum_i\sum_j\alpha_i\alpha_j E_j&&\text{since \(\ran(E_i)=\ran(E_j)\)}\\
	&=\bigl(\,\sum_i\alpha_i\bigr)\bigl(\,\sum_j\alpha_jE_j\bigr)&&\\
	&=1\cdot E&&\text{since \(\textstyle\sum_i\alpha_i=1\)}\\
	&=E
\end{align*}
Therefore \(E\)~is idempotent, and hence a projection (Theorem~41.1).
\end{proof}

% References
\begin{thebibliography}{0}
\bibitem{halmos87} Halmos, P. \textit{Finite Dimensional Vector Spaces.} Springer, 1987.
\end{thebibliography}
\end{document}